# RoninNVR Docker Compose Configuration
#
# Usage:
#   docker compose up -d                    # Start all services (live detection only)
#   docker compose --profile historical up -d  # Include historical ML processing
#   docker compose logs -f backend          # View backend logs
#   docker compose down                     # Stop all services
#
# ML Processing Modes:
#   - live-detection: Real-time alerts from live streams (default, ~2-5s latency)
#   - ml-worker: Historical analysis of completed recordings (use --profile historical)
#   - Both can run together if you want real-time alerts AND deeper historical analysis
#
# GPU Support:
#   Requires nvidia-container-toolkit installed on host
#   GPU services will use NVIDIA runtime automatically

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: ronin-postgres
    restart: unless-stopped
    user: "1000:1000"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-ronin_nvr_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ronin_pass}
      POSTGRES_DB: ${POSTGRES_DB:-ronin_nvr}
    volumes:
      - /opt2/ronin/postgres:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-ronin_nvr_user} -d ${POSTGRES_DB:-ronin_nvr}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ronin-backend
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-ronin_nvr_user}:${POSTGRES_PASSWORD:-ronin_pass}@postgres:5432/${POSTGRES_DB:-ronin_nvr}
      STORAGE_ROOT: /data/storage
      HOST: 0.0.0.0
      PORT: 8000
      DEBUG: ${DEBUG:-false}
      TZ: ${TZ:-America/Denver}
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-change-me-in-production}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY:-}
      DEFAULT_ADMIN_PASSWORD: ${DEFAULT_ADMIN_PASSWORD:-}
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost,http://localhost:3000,http://192.168.1.127}
      ML_ENABLED: "true"
      ML_AUTO_PROCESS: "true"
    volumes:
      - /opt3/ronin/storage:/data/storage
      - /opt3/ronin/ml_models:/data/storage/.ml/models
    ports:
      - "8000:8000"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/api/health')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # React Frontend (Nginx)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ronin-frontend
    restart: unless-stopped
    depends_on:
      - backend
    ports:
      - "80:80"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ML Worker - Historical Analysis (processes completed recordings)
  # Use --profile historical to enable: docker compose --profile historical up -d
  ml-worker:
    profiles:
      - historical
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
    restart: unless-stopped
    user: "1000:1000"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-ronin_nvr_user}:${POSTGRES_PASSWORD:-ronin_pass}@postgres:5432/${POSTGRES_DB:-ronin_nvr}
      STORAGE_ROOT: /data/storage
      TZ: ${TZ:-America/Denver}
      ML_WORKERS: 1
      ML_DEFAULT_FPS: ${ML_DEFAULT_FPS:-2.0}
      ML_CONFIDENCE_THRESHOLD: ${ML_CONFIDENCE_THRESHOLD:-0.5}
      ML_CLASS_FILTER: ${ML_CLASS_FILTER:-person,car,truck,bus,motorcycle,bicycle,dog,cat}
    volumes:
      - /opt3/ronin/storage:/data/storage
      - /opt3/ronin/ml_models:/data/storage/.ml/models
    command: ["python", "ml_worker.py", "--workers", "1"]
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Live Detection Worker (single instance, monitors all cameras)
  live-detection:
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
    container_name: ronin-live-detection
    restart: unless-stopped
    user: "1000:1000"
    depends_on:
      postgres:
        condition: service_healthy
      backend:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql+asyncpg://${POSTGRES_USER:-ronin_nvr_user}:${POSTGRES_PASSWORD:-ronin_pass}@postgres:5432/${POSTGRES_DB:-ronin_nvr}
      STORAGE_ROOT: /data/storage
      TZ: ${TZ:-America/Denver}
      LIVE_DETECTION_ENABLED: ${LIVE_DETECTION_ENABLED:-true}
      LIVE_DETECTION_FPS: ${LIVE_DETECTION_FPS:-1.0}
      LIVE_DETECTION_COOLDOWN: ${LIVE_DETECTION_COOLDOWN:-30.0}
      LIVE_DETECTION_CONFIDENCE: ${LIVE_DETECTION_CONFIDENCE:-0.6}
      LIVE_DETECTION_CLASSES: ${LIVE_DETECTION_CLASSES:-person,car,truck}
      ML_CONFIDENCE_THRESHOLD: ${ML_CONFIDENCE_THRESHOLD:-0.5}
      ML_CLASS_FILTER: ${ML_CLASS_FILTER:-person,car,truck,bus,motorcycle,bicycle,dog,cat}
    volumes:
      - /opt3/ronin/storage:/data/storage
      - /opt3/ronin/ml_models:/data/storage/.ml/models
    command: ["python", "live_detection_worker.py"]
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Transcode Worker (runs 3 replicas)
  transcode-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile.worker
    restart: unless-stopped
    user: "1000:1000"
    depends_on:
      - backend
    environment:
      STORAGE_ROOT: /data/storage
      TZ: ${TZ:-America/Denver}
      TRANSCODE_CRF: ${TRANSCODE_CRF:-28}
      TRANSCODE_PRESET: ${TRANSCODE_PRESET:-medium}
    volumes:
      - /opt3/ronin/storage:/data/storage
    command: ["python", "transcode_worker.py", "--continuous"]
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '4'
          memory: 2G
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu, video]

volumes:
  postgres_data:
    name: ronin_postgres_data
  storage_data:
    name: ronin_storage_data
  ml_models:
    name: ronin_ml_models

networks:
  default:
    name: ronin_network
